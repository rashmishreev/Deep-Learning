{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512a464f",
   "metadata": {},
   "source": [
    "### Problem 1: Apply the following models on the Fashion Mnist Dataset. Train the model with the training data and evaluate the model with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61bcf5f",
   "metadata": {},
   "source": [
    "### a. CNN model from scratch\n",
    "Develop a CNN model with 5 convolutional layers (with kernel size= 3, stride =1, padding = “same”, activation function = “relu”) with following MaxPooling layer (Size= 2) and 3 fully connected layer (including one output layer). After each of the Convolutional layer apply Batch Normalization. In the fully connected layer apply dropout (rate 0.50). Show the learning curve. Report performance evaluation on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2cf86e",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6618b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.keras.activations import relu, elu\n",
    "from tensorflow.keras.callbacks import History\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e4ec2d",
   "metadata": {},
   "source": [
    "### Loading the Fashion Mnist data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a50682da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Reshaping and preprocessing the training images\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255 # Reshape the training images array to have 60,000 samples, each of which is a 28x28 pixel image with a single channel.\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10a93c",
   "metadata": {},
   "source": [
    "### Building the CNN model and adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91d375aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Adding Convolutional layer 1 with 32 filters, a filter size of (3, 3), using strides of (1, 1), 'same' padding, and ReLU activation. \n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Adding a Batch Normalization layer to normalize the activations of the previous layer.\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Adding a Max Pooling layer with a pool size of (2, 2) to perform down-sampling.\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding Convolutional layer 2 with 64 filters\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Adding Convolutional layer 3 with 128 filters\n",
    "model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Adding Convolutional layer 4 with 256 filters\n",
    "model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Adding Convolutional layer 5 with 512 filters\n",
    "model.add(layers.Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Flatten the previous layer to convert the data into a 1D array for input into the Dense layers.\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Adding Dense layer with 512 neurons and ReLU activation\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Adding a Dropout layer to prevent overfitting\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "#Adding another Dense layer with 256 neurons\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Adding a final Dense layer with 10 neurons and softmax activation for multi-class classification.\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badca21b",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae8ad1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c9fcb",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d6fac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 708s 2s/step - loss: 0.8035 - accuracy: 0.7648 - val_loss: 5.5054 - val_accuracy: 0.5455\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 641s 2s/step - loss: 0.3991 - accuracy: 0.8643 - val_loss: 0.3059 - val_accuracy: 0.8867\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 530s 1s/step - loss: 0.3027 - accuracy: 0.8944 - val_loss: 0.2833 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 526s 1s/step - loss: 0.2608 - accuracy: 0.9091 - val_loss: 0.2633 - val_accuracy: 0.9034\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 529s 1s/step - loss: 0.2447 - accuracy: 0.9137 - val_loss: 0.2686 - val_accuracy: 0.9095\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN model on the provided training data and labels for 5 epochs\n",
    "#using a batch size of 128 and a 20% validation split for monitoring the model's performance.\n",
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e61d7b",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f496ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 79ms/step - loss: 0.3067 - accuracy: 0.9018\n",
      "Test accuracy: 0.9017999768257141\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3332a0",
   "metadata": {},
   "source": [
    "#### The reported accuracy on Test is: 0.9017999768257141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185adfeb",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03f4811d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the learning curve\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc992e8",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e43f1614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_192 (Conv2D)         (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_184 (B  (None, 28, 28, 32)        128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_185 (B  (None, 14, 14, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_186 (B  (None, 7, 7, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_187 (B  (None, 7, 7, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 7, 7, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_188 (B  (None, 7, 7, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8028938 (30.63 MB)\n",
      "Trainable params: 8026954 (30.62 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c7d1f",
   "metadata": {},
   "source": [
    "### b. Apply 5-Fold Cross Validation on the CNN model developed in (a) and report the average accuracy with standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08ac4d",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries, loading and pre-processing the Fashion MNIST data as in previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f89b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, utils\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load Fashion MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9174d98",
   "metadata": {},
   "source": [
    "#### Creating the CNN model similar to (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b112b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "def create_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 5 Convolutional layers with Batch Normalization and MaxPooling\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a85f2bd",
   "metadata": {},
   "source": [
    "### Performing 5-fold cross validation and calculating the avg accuracy and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70a6a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "375/375 [==============================] - 541s 1s/step - loss: 0.7716 - accuracy: 0.7763 - val_loss: 2.4032 - val_accuracy: 0.7273\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 544s 1s/step - loss: 0.4358 - accuracy: 0.8586 - val_loss: 0.4152 - val_accuracy: 0.8808\n",
      "313/313 - 24s - loss: 0.4192 - accuracy: 0.8776 - 24s/epoch - 77ms/step\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 2246s 6s/step - loss: 0.8204 - accuracy: 0.7650 - val_loss: 1.6018 - val_accuracy: 0.5418\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 546s 1s/step - loss: 0.3934 - accuracy: 0.8686 - val_loss: 0.3915 - val_accuracy: 0.8807\n",
      "313/313 - 25s - loss: 0.4187 - accuracy: 0.8776 - 25s/epoch - 80ms/step\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 532s 1s/step - loss: 0.8341 - accuracy: 0.7590 - val_loss: 56.4212 - val_accuracy: 0.2085\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 538s 1s/step - loss: 0.4169 - accuracy: 0.8583 - val_loss: 0.3105 - val_accuracy: 0.8914\n",
      "313/313 - 27s - loss: 0.3358 - accuracy: 0.8825 - 27s/epoch - 85ms/step\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 657s 2s/step - loss: 0.8061 - accuracy: 0.7702 - val_loss: 27.3161 - val_accuracy: 0.2720\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 1639s 4s/step - loss: 0.3612 - accuracy: 0.8771 - val_loss: 0.3319 - val_accuracy: 0.8896\n",
      "313/313 - 26s - loss: 0.3488 - accuracy: 0.8831 - 26s/epoch - 83ms/step\n",
      "Epoch 1/2\n",
      "375/375 [==============================] - 547s 1s/step - loss: 0.8811 - accuracy: 0.7446 - val_loss: 13.9537 - val_accuracy: 0.5340\n",
      "Epoch 2/2\n",
      "375/375 [==============================] - 606s 2s/step - loss: 0.3876 - accuracy: 0.8678 - val_loss: 0.3160 - val_accuracy: 0.8913\n",
      "313/313 - 26s - loss: 0.3304 - accuracy: 0.8855 - 26s/epoch - 82ms/step\n",
      "Average accuracy: 0.8812600016593933\n",
      "Standard deviation: 0.0031525162292539545\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kfold.split(train_images):\n",
    "    X_train, X_val = train_images[train_index], train_images[test_index]\n",
    "    y_train, y_val = train_labels[train_index], train_labels[test_index]\n",
    "\n",
    "    model = create_model()\n",
    "    model.fit(X_train, y_train, epochs=2, batch_size=128, validation_data=(X_val, y_val))\n",
    "    _, accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy and standard deviation\n",
    "average_accuracy = np.mean(accuracies)\n",
    "std_deviation = np.std(accuracies)\n",
    "\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Standard deviation:\", std_deviation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a832dc",
   "metadata": {},
   "source": [
    "### The Average accuracy is: 0.8812600016593933\n",
    "### The Standard deviation is: 0.0031525162292539545"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194fa09",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4ba590f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_192 (Conv2D)         (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_184 (B  (None, 28, 28, 32)        128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_193 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_185 (B  (None, 14, 14, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_194 (Conv2D)         (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_186 (B  (None, 7, 7, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_195 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_187 (B  (None, 7, 7, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_196 (Conv2D)         (None, 7, 7, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_188 (B  (None, 7, 7, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8028938 (30.63 MB)\n",
      "Trainable params: 8026954 (30.62 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c81b8f",
   "metadata": {},
   "source": [
    "### c. Grid Search\n",
    "Apply grid search on the CNN model to find the optimal set of hyperparameters that produce the max performance on the test data. You must train the model using the training data and evaluate model performance using the test dataset. Use grid search for hyperparameter tuning with the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6060c13",
   "metadata": {},
   "source": [
    "### Importing necessary libraries, loading and pre-processing the Fashion MNIST data as in previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ad10bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "import itertools\n",
    "\n",
    "# Load the Fashion MNIST data\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8387f7d",
   "metadata": {},
   "source": [
    "### Grid search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bfe712e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3750/3750 [==============================] - 1150s 306ms/step - loss: 1.3809 - accuracy: 0.4916 - val_loss: 0.9565 - val_accuracy: 0.5715\n",
      "Epoch 2/2\n",
      "3750/3750 [==============================] - 1001s 267ms/step - loss: 0.9276 - accuracy: 0.6047 - val_loss: 0.7559 - val_accuracy: 0.7188\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.7559 - accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3750/3750 [==============================] - 994s 264ms/step - loss: 1.5460 - accuracy: 0.4196 - val_loss: 1.2007 - val_accuracy: 0.4715\n",
      "Epoch 2/2\n",
      "3750/3750 [==============================] - 984s 262ms/step - loss: 1.2218 - accuracy: 0.4703 - val_loss: 1.1574 - val_accuracy: 0.4794\n",
      "313/313 [==============================] - 26s 83ms/step - loss: 1.1574 - accuracy: 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3750/3750 [==============================] - 1071s 285ms/step - loss: 1.3469 - accuracy: 0.5252 - val_loss: 0.9116 - val_accuracy: 0.6626\n",
      "Epoch 2/2\n",
      "3750/3750 [==============================] - 1006s 268ms/step - loss: 0.8234 - accuracy: 0.6631 - val_loss: 0.5968 - val_accuracy: 0.7521\n",
      "313/313 [==============================] - 27s 85ms/step - loss: 0.5969 - accuracy: 0.7521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 778s 412ms/step - loss: 1.1834 - accuracy: 0.5872 - val_loss: 0.7646 - val_accuracy: 0.6725\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 802s 428ms/step - loss: 0.7314 - accuracy: 0.7038 - val_loss: 0.5663 - val_accuracy: 0.7659\n",
      "313/313 [==============================] - 26s 85ms/step - loss: 0.5663 - accuracy: 0.7659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  18/1875 [..............................] - ETA: 13:28 - loss: 5.0094 - accuracy: 0.3438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 48\u001b[0m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer(lr\u001b[38;5;241m=\u001b[39mlr),\n\u001b[1;32m     44\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Train the model for 2 epochs and validate it on the test data.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_images, train_labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(test_images, test_labels))\n\u001b[1;32m     49\u001b[0m _, test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Store the test accuracy in the results dictionary with corresponding hyperparameter settings as the key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function(\u001b[38;5;241m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "activation_functions = [tf.nn.relu, LeakyReLU(alpha=0.3)]  # Define activation functions: ReLU and Leaky ReLU.\n",
    "optimizers = [Adam, Adagrad]  # Define optimizers: Adam and Adagrad.\n",
    "batch_sizes = [16, 32, 64]  # Define batch sizes to be used during training.\n",
    "learning_rates = [0.001, 0.0001, 0.00001]  # Define learning rates for the optimizers.\n",
    "\n",
    "\n",
    "results = {} # Initialize an empty dictionary to store the results of the experiments.\n",
    "\n",
    "# Iterate through all combinations of activation functions, optimizers, batch sizes, and learning rates.\n",
    "for activation, optimizer, batch_size, lr in itertools.product(activation_functions, optimizers, batch_sizes, learning_rates):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # 5 CNN Layers\n",
    "    model.add(Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # Compile the model with the selected optimizer, loss function, and metrics.\n",
    "    model.compile(optimizer=optimizer(lr=lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model for 2 epochs and validate it on the test data.\n",
    "    history = model.fit(train_images, train_labels, epochs=2, batch_size=batch_size, validation_data=(test_images, test_labels))\n",
    "    _, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "    \n",
    "    # Store the test accuracy in the results dictionary with corresponding hyperparameter settings as the key.\n",
    "    results[(activation.__name__, optimizer.__name__, batch_size, lr)] = test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d329d75",
   "metadata": {},
   "source": [
    "### Finding the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c2bd6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hyperparameters = max(results, key=results.get)\n",
    "max_accuracy = results[optimal_hyperparameters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a158a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed3ed14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter Combinations and Test Accuracies:\n",
      "('relu', 'Adam', 16, 0.001) 0.7188000082969666\n",
      "('relu', 'Adam', 16, 0.0001) 0.47940000891685486\n",
      "('relu', 'Adam', 16, 1e-05) 0.7520999908447266\n",
      "('relu', 'Adam', 32, 0.001) 0.7659000158309937\n",
      "\n",
      "Optimal Hyperparameters:\n",
      "('relu', 'Adam', 32, 0.001) with Test Accuracy: 0.7659000158309937\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHyperparameter Combinations and Test Accuracies:\")\n",
    "for hyperparameters, accuracy in results.items():\n",
    "    print(f\"{hyperparameters} {accuracy}\")\n",
    "\n",
    "print(\"\\nOptimal Hyperparameters:\")\n",
    "print(f\"{optimal_hyperparameters} with Test Accuracy: {max_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9268dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_217 (Conv2D)         (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_209 (B  (None, 28, 28, 32)        128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPooli  (None, 14, 14, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_218 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_210 (B  (None, 14, 14, 64)        256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPooli  (None, 7, 7, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_219 (Conv2D)         (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_211 (B  (None, 7, 7, 128)         512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_220 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_212 (B  (None, 7, 7, 256)         1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_221 (Conv2D)         (None, 7, 7, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_213 (B  (None, 7, 7, 512)         2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8028938 (30.63 MB)\n",
      "Trainable params: 8026954 (30.62 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ff39e",
   "metadata": {},
   "source": [
    "### d. Data Augmentation\n",
    "Apply five different image augmentation techniques on the Fashion Mnist train data to augment it and then apply the previously designed (from a) model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a978b",
   "metadata": {},
   "source": [
    "#### Necessary imports, loading the Fashion MNIST data and Pre-proccessing it, similarly as done for above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19f5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Load Fashion MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Data preprocessing\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deea873",
   "metadata": {},
   "source": [
    "#### Image data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations applied to the input images during data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data augmentation generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41942b",
   "metadata": {},
   "source": [
    "### Define the CNN model similar to (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Convolutional layer 1 with 16 filters\n",
    "model.add(layers.Conv2D(16, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6dfbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional layer 2 with 32 filters\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolutional layer 3 with 64 filters\n",
    "model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Convolutional layer 4 with 128 filters\n",
    "model.add(layers.Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "# Convolutional layer 5 with 256 filters\n",
    "model.add(layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36e0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 328s 173ms/step - loss: 1.1491 - accuracy: 0.6017\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 290s 155ms/step - loss: 0.7484 - accuracy: 0.7026\n",
      "Test Accuracy: 0.7563999891281128\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using augmented data\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=32), steps_per_epoch=len(x_train) / 32, epochs=2)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd8a47",
   "metadata": {},
   "source": [
    "### Evaluation results: 0.7563999891281128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad5b20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 28, 28, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 14, 14, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 7, 7, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 7, 7, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 7, 7, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               3211520   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3640010 (13.89 MB)\n",
      "Trainable params: 3639018 (13.88 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efb7cc",
   "metadata": {},
   "source": [
    "### e. Transfer Learning\n",
    "Load the VGG-19 model. Drop after the block4 conv1 layer (highlighted in the image below) and on top of it add one global average pooling layer, one fully connected layer, and one final output layer. Keep the base model layers (VGG19) freeze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3302e1",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "088362c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b260ed",
   "metadata": {},
   "source": [
    "### Load the pre-trained VGG-19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915f6323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730ec41",
   "metadata": {},
   "source": [
    "### Base Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b4208c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20024384 (76.39 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1217b",
   "metadata": {},
   "source": [
    "#### Freezing the layers in the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0abe8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a61b5",
   "metadata": {},
   "source": [
    "#### Getting the index of the layer (block4 conv1) after which to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc8ed16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index_to_drop = 12  # This index corresponds to block4_conv1 layer in VGG-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6fea81",
   "metadata": {},
   "source": [
    "#### Creating a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf8a6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=base_model.input, outputs=base_model.layers[layer_index_to_drop].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f4f12",
   "metadata": {},
   "source": [
    "#### New model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2008331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3505728 (13.37 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 3505728 (13.37 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "206954cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output of the last convolutional layer in block4\n",
    "x = base_model.get_layer('block4_conv1').output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3635e85",
   "metadata": {},
   "source": [
    "#### Adding one global average pooling layer, one fully connected layer, and one final output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e56690a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_3  (None, 512)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3639626 (13.88 MB)\n",
      "Trainable params: 133898 (523.04 KB)\n",
      "Non-trainable params: 3505728 (13.37 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add a global average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Add the final output layer\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Creating the final model\n",
    "final_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compiling the model\n",
    "final_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model Summary after dropping the layers below block4_conv1 and adding the global average pooling, \n",
    "# fully connected and final output layer\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccee05",
   "metadata": {},
   "source": [
    "### Problem 2: Developing ResNet model from scratch\n",
    "Apply a residual network specified in the following architecture. All convolutional layers use kernel size 3, stride = 1, and padding = “same”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fcb03",
   "metadata": {},
   "source": [
    "Link to shared google drive with code and .h5 file of the model: https://drive.google.com/drive/u/0/folders/0ACThGuV5YRYxUk9PVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aadf22",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d1e2c7",
   "metadata": {},
   "source": [
    "### Building the residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b323ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, kernel_size=3, strides=1):\n",
    "    y = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = ReLU()(y)\n",
    "    y = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    if x.shape[-1] != y.shape[-1]:\n",
    "        x = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "    return Add()([y, x]), ReLU()(Add()([y, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33906423",
   "metadata": {},
   "source": [
    "### Building the ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape=(28, 28, 1), num_classes=10):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, 3, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Section A: Iterate through 3 residual blocks with 32 filters.\n",
    "    for _ in range(3):\n",
    "        x, _ = residual_block(x, 32)\n",
    "\n",
    "    # Section B: Iterate through 3 residual blocks with 64 filters.\n",
    "    for _ in range(3):\n",
    "        x, _ = residual_block(x, 64)\n",
    "\n",
    "    # Section C: Iterate through 3 residual blocks with 128 filters.\n",
    "    for _ in range(3):\n",
    "        x, _ = residual_block(x, 128)\n",
    "\n",
    "    #Add a Global Average Pooling and Dense Layer\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, x) # Define the model with the specified input and output layers.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d857a21",
   "metadata": {},
   "source": [
    "#### Load Fashion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a906a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bdf81",
   "metadata": {},
   "source": [
    "#### Create and compiling the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d240b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = resnet()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f175fa",
   "metadata": {},
   "source": [
    "#### Saving the model in .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a272e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model in .h5\n",
    "model.save('resnet_fashion_mnist.h5')\n",
    "\n",
    "# Loading the trained model from the model file\n",
    "loaded_model = tf.keras.models.load_model('resnet_fashion_mnist.h5')\n",
    "\n",
    "# Return the loaded model\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27866b7e",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c770045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 232s 738ms/step - loss: 2.3410 - accuracy: 0.0385\n",
      "Test loss: 2.341022491455078\n",
      "Test accuracy: 0.03849999979138374\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = loaded_model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56cfc3",
   "metadata": {},
   "source": [
    "#### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f8b1344",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)         (None, 28, 28, 32)           320       ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_135 (B  (None, 28, 28, 32)           128       ['conv2d_141[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)             (None, 28, 28, 32)           0         ['batch_normalization_135[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)         (None, 28, 28, 32)           9248      ['re_lu_65[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_136 (B  (None, 28, 28, 32)           128       ['conv2d_142[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)             (None, 28, 28, 32)           0         ['batch_normalization_136[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)         (None, 28, 28, 32)           9248      ['re_lu_66[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_137 (B  (None, 28, 28, 32)           128       ['conv2d_143[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_61 (Add)                (None, 28, 28, 32)           0         ['batch_normalization_137[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     're_lu_65[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)         (None, 28, 28, 32)           9248      ['add_61[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_138 (B  (None, 28, 28, 32)           128       ['conv2d_144[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)             (None, 28, 28, 32)           0         ['batch_normalization_138[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)         (None, 28, 28, 32)           9248      ['re_lu_68[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_139 (B  (None, 28, 28, 32)           128       ['conv2d_145[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_63 (Add)                (None, 28, 28, 32)           0         ['batch_normalization_139[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_61[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)         (None, 28, 28, 32)           9248      ['add_63[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_140 (B  (None, 28, 28, 32)           128       ['conv2d_146[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)             (None, 28, 28, 32)           0         ['batch_normalization_140[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)         (None, 28, 28, 32)           9248      ['re_lu_70[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_141 (B  (None, 28, 28, 32)           128       ['conv2d_147[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_65 (Add)                (None, 28, 28, 32)           0         ['batch_normalization_141[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_63[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)         (None, 28, 28, 64)           18496     ['add_65[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_142 (B  (None, 28, 28, 64)           256       ['conv2d_148[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)             (None, 28, 28, 64)           0         ['batch_normalization_142[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)         (None, 28, 28, 64)           36928     ['re_lu_72[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_143 (B  (None, 28, 28, 64)           256       ['conv2d_149[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)         (None, 28, 28, 64)           2112      ['add_65[0][0]']              \n",
      "                                                                                                  \n",
      " add_67 (Add)                (None, 28, 28, 64)           0         ['batch_normalization_143[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv2d_150[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_151 (Conv2D)         (None, 28, 28, 64)           36928     ['add_67[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_144 (B  (None, 28, 28, 64)           256       ['conv2d_151[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)             (None, 28, 28, 64)           0         ['batch_normalization_144[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)         (None, 28, 28, 64)           36928     ['re_lu_74[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_145 (B  (None, 28, 28, 64)           256       ['conv2d_152[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_69 (Add)                (None, 28, 28, 64)           0         ['batch_normalization_145[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_67[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)         (None, 28, 28, 64)           36928     ['add_69[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_146 (B  (None, 28, 28, 64)           256       ['conv2d_153[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)             (None, 28, 28, 64)           0         ['batch_normalization_146[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)         (None, 28, 28, 64)           36928     ['re_lu_76[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_147 (B  (None, 28, 28, 64)           256       ['conv2d_154[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_71 (Add)                (None, 28, 28, 64)           0         ['batch_normalization_147[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_69[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)         (None, 28, 28, 128)          73856     ['add_71[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_148 (B  (None, 28, 28, 128)          512       ['conv2d_155[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)             (None, 28, 28, 128)          0         ['batch_normalization_148[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)         (None, 28, 28, 128)          147584    ['re_lu_78[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_149 (B  (None, 28, 28, 128)          512       ['conv2d_156[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)         (None, 28, 28, 128)          8320      ['add_71[0][0]']              \n",
      "                                                                                                  \n",
      " add_73 (Add)                (None, 28, 28, 128)          0         ['batch_normalization_149[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'conv2d_157[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)         (None, 28, 28, 128)          147584    ['add_73[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_150 (B  (None, 28, 28, 128)          512       ['conv2d_158[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)             (None, 28, 28, 128)          0         ['batch_normalization_150[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)         (None, 28, 28, 128)          147584    ['re_lu_80[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_151 (B  (None, 28, 28, 128)          512       ['conv2d_159[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " add_75 (Add)                (None, 28, 28, 128)          0         ['batch_normalization_151[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_73[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)         (None, 28, 28, 128)          147584    ['add_75[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_152 (B  (None, 28, 28, 128)          512       ['conv2d_160[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)             (None, 28, 28, 128)          0         ['batch_normalization_152[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)         (None, 28, 28, 128)          147584    ['re_lu_82[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_153 (B  (None, 28, 28, 128)          512       ['conv2d_161[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_77 (Add)                (None, 28, 28, 128)          0         ['batch_normalization_153[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_75[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (None, 128)                  0         ['add_77[0][0]']              \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_51 (Dense)            (None, 10)                   1290      ['global_average_pooling2d_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1087946 (4.15 MB)\n",
      "Trainable params: 1085194 (4.14 MB)\n",
      "Non-trainable params: 2752 (10.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
